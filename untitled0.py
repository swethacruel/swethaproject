# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xjsAPBvqDvUSvX_BUC2fJTTSNsaz1EKo
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

file_path = '/content/drive/MyDrive/global_traffic_accidents.csv'
df = pd.read_csv(file_path)

df.head()

# prompt: Using dataframe df: Heatmap

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Assuming 'df' is your DataFrame

# Create a contingency table (cross-tabulation)
contingency_table = pd.crosstab(df['Weather Condition'], df['Road Condition'])

# Create the heatmap
plt.figure(figsize=(10, 8))  # Adjust figure size as needed
sns.heatmap(contingency_table, annot=True, fmt='d', cmap='viridis', cbar=True) #annot=True to show values
plt.title('Heatmap of Weather Condition vs. Road Condition')
plt.xlabel('Road Condition')
plt.ylabel('Weather Condition')
plt.show()

import pandas as pd
from sklearn.preprocessing import LabelEncoder

# Load dataset
df = pd.read_csv('/content/drive/MyDrive/global_traffic_accidents.csv')

# View initial info
print("Before Preprocessing:")
print(df.info())

# Keep only relevant columns
# Changed 'Weather_Condition' to 'Weather Condition' to match the actual column name
df = df[['Weather Condition', 'Casualties']]

# Fill missing values
# Changed 'Weather_Condition' to 'Weather Condition' to match the actual column name
df['Weather Condition'] = df['Weather Condition'].fillna('Clear')
df['Casualties'] = df['Casualties'].fillna(df['Casualties'].median())

# Remove duplicates
df = df.drop_duplicates()

# Encode 'Weather Condition'
le = LabelEncoder()
# Changed 'Weather_Condition' to 'Weather Condition' to match the actual column name
df['Weather Condition'] = le.fit_transform(df['Weather Condition'])

print("\nAfter Preprocessing:")
print(df.info())

# Preview the dataset
df.head()

# prompt: Using dataframe df: pie chart

import altair as alt

# Calculate the sum of casualties for each weather condition
casualties_by_weather = df.groupby('Weather Condition')['Casualties'].sum().reset_index()

# Create the pie chart
alt.Chart(casualties_by_weather).mark_arc().encode(
    theta='Casualties',
    color='Weather Condition'
)

import seaborn as sns
import matplotlib.pyplot as plt

# Load the original dataset to have access to 'Road_Condition'
original_df = pd.read_csv('/content/drive/MyDrive/global_traffic_accidents.csv')

# Plot distribution of Road Condition using the original DataFrame
# Changed 'Road_Condition' to 'Road Condition' to match the actual column name
sns.countplot(data=original_df, x='Road Condition')
plt.title("Road Condition Distribution")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Continue with the correlation heatmap using the preprocessed df
plt.figure(figsize=(10,8))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
plt.title("Feature Correlation Heatmap")
plt.show()

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import StandardScaler # Importing the scaler
import pandas as pd # Importing pandas to load the data

# Load dataset ensuring it is the preprocessed one
df = pd.read_csv('/content/drive/MyDrive/global_traffic_accidents.csv')
df = df[['Weather Condition', 'Casualties']]
df['Weather Condition'] = df['Weather Condition'].fillna('Clear')
df['Casualties'] = df['Casualties'].fillna(df['Casualties'].median())
df = df.drop_duplicates()
from sklearn.preprocessing import LabelEncoder # Importing LabelEncoder
le = LabelEncoder()
df['Weather Condition'] = le.fit_transform(df['Weather Condition'])

# Assuming 'df' is your DataFrame and you want to use 'Weather Condition' as features and 'Casualties' as target
X = df[['Weather Condition']]
y = df['Casualties']

# Scale the features using StandardScaler
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X) # Scaling the features

# Split data
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Train model
model = RandomForestClassifier()
model.fit(X_train, y_train)

# Predict
y_pred = model.predict(X_test)

# Evaluate
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

from google.colab import drive
drive.mount('/content/drive')

# Import libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Load dataset
df = pd.read_csv('/content/drive/MyDrive/global_traffic_accidents.csv')  # Adjust path if needed

# Display basic info
print("Before Preprocessing:")
print(df.info())

# Drop irrelevant columns
df.drop(['Accident ID', 'Date', 'Time', 'Location', 'Latitude', 'Longitude'], axis=1, inplace=True)

# Handle missing values (if any)
df = df.dropna()

# Label Encoding for categorical columns
le = LabelEncoder()
df['Weather Condition'] = le.fit_transform(df['Weather Condition'])
df['Road Condition'] = le.fit_transform(df['Road Condition'])
df['Cause'] = le.fit_transform(df['Cause'])

# Features and Target
X = df.drop('Road Condition', axis=1)
y = df['Road Condition']

# Feature Scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split data
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Train model
model = RandomForestClassifier()
model.fit(X_train, y_train)

# Predict
y_pred = model.predict(X_test)

# Evaluation
print("\nAccuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))

# Visualization: Feature correlation
plt.figure(figsize=(8, 6))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
plt.title("Feature Correlation Heatmap")
plt.show()

# Visualization: Road Condition distribution
sns.countplot(x='Road Condition', data=df)
plt.title("Road Condition Distribution")
plt.show()